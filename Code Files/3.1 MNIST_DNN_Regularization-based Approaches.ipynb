{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNx17GqDfwE5AiP0swx6Y8c"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["\n","# Final layer updation of a pre-trained model, if new classes come in the target dataset\n","\n"],"metadata":{"id":"YWKbJXOz_6og"}},{"cell_type":"markdown","source":["## Code Functions used throughout"],"metadata":{"id":"biwSALWFvOme"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"QcXUepUXvqyB","executionInfo":{"status":"ok","timestamp":1730584599760,"user_tz":-330,"elapsed":1884,"user":{"displayName":"Yash Sarang","userId":"15641196399800805733"}}},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","import tensorflow.keras  as keras\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.models import clone_model\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","from collections import Counter"]},{"cell_type":"code","source":["def accuracy_per_label(model_name):\n","  # Predict the labels for the test set\n","  y_pred = np.argmax(model_name.predict(x_test_full), axis=1)\n","\n","  # Calculate accuracy for each label (0-9)\n","  label_accuracies = {}\n","  for label in range(10):\n","    # Get indices where the true label is equal to the current label\n","    label_indices = np.where(y_test_full == label)[0]\n","\n","    # Get the true and predicted labels for the current label\n","    y_true_label = y_test_full[label_indices]\n","    y_pred_label = y_pred[label_indices]\n","\n","    # Calculate accuracy for the current label\n","    accuracy = accuracy_score(y_true_label, y_pred_label)\n","    label_accuracies[label] = accuracy\n","\n","  # Print the accuracy for each label\n","  for label, accuracy in label_accuracies.items():\n","    print(f'Accuracy for label {label}: {accuracy * 100:.2f}%')\n","\n","  total_accuracy = accuracy_score(y_test_full, y_pred)\n","  print(f'Total accuracy: {total_accuracy * 100:.2f}%')\n","\n","  return True"],"metadata":{"id":"eMN4K3eWDr39","executionInfo":{"status":"ok","timestamp":1730584599761,"user_tz":-330,"elapsed":3,"user":{"displayName":"Yash Sarang","userId":"15641196399800805733"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def pred_label_count(model_name):\n","  # Predict the labels for the test set\n","  y_pred = np.argmax(model_name.predict(x_test_full), axis=1)\n","\n","  # Count how many times each label was predicted\n","  predicted_label_counts = Counter(y_pred)\n","\n","  # Print the number of times each label was predicted\n","  for label, count in sorted(predicted_label_counts.items()):\n","    print(f'Label {label} was predicted {count} times')"],"metadata":{"id":"50tLLGK8GUu1","executionInfo":{"status":"ok","timestamp":1730584599761,"user_tz":-330,"elapsed":3,"user":{"displayName":"Yash Sarang","userId":"15641196399800805733"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Define an EarlyStopping callback with a custom stopping condition for 100% validation accuracy\n","class CustomStopping(EarlyStopping):\n","    def __init__(self, monitor='train_accuracy', value=1.0, verbose=1, **kwargs):\n","        super(CustomStopping, self).__init__(monitor=monitor, verbose=verbose, **kwargs)\n","        self.value = value\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        current = logs.get(self.monitor)\n","        if current is not None and current >= self.value:\n","            self.stopped_epoch = epoch\n","            self.model.stop_training = True\n","\n","# Use CustomStopping callback to stop training at 100% test accuracy\n","early_stopping_accuracy = CustomStopping(monitor='train_accuracy', value=1.0, verbose=1)\n","\n","# Using EarlyStopping based on validation loss with a patience parameter\n","early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, verbose=1, restore_best_weights=True)\n","\n"],"metadata":{"id":"UT3TVz2LhBUL","executionInfo":{"status":"ok","timestamp":1730584599761,"user_tz":-330,"elapsed":2,"user":{"displayName":"Yash Sarang","userId":"15641196399800805733"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["\n","def show_misclassified_samples(model, x_test, y_test, num_samples=5):\n","    \"\"\"\n","    Displays the misclassified samples from the test set.\n","\n","    Parameters:\n","    - model: Trained model\n","    - x_test: Test data\n","    - y_test: True labels for the test data\n","    - num_samples: Number of misclassified samples to display (default: 5)\n","    \"\"\"\n","    # Get the model's predictions\n","    y_pred = np.argmax(model.predict(x_test), axis=1)\n","\n","    # Find the indices of misclassified samples\n","    misclassified_indices = np.where(y_pred != y_test)[0]\n","\n","    # If there are no misclassified samples\n","    if len(misclassified_indices) == 0:\n","        print(\"All samples were classified correctly.\")\n","        return\n","\n","    # Display the number of misclassified samples\n","    print(f\"Total misclassified samples: {len(misclassified_indices)} out of {len(x_test)}\")\n","\n","    # Display a few misclassified samples (up to 'num_samples')\n","    plt.figure(figsize=(10, 10))\n","    for i, index in enumerate(misclassified_indices[:num_samples]):\n","        plt.subplot(1, num_samples, i + 1)\n","        plt.imshow(x_test[index].reshape(28, 28), cmap='gray')\n","        plt.title(f\"True: {y_test[index]}, Pred: {y_pred[index]}\")\n","        plt.axis('off')\n","\n","    plt.show()"],"metadata":{"id":"aUioO3DblK-r","executionInfo":{"status":"ok","timestamp":1730584599761,"user_tz":-330,"elapsed":2,"user":{"displayName":"Yash Sarang","userId":"15641196399800805733"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Final Results (MNIST with DNN)\n","\n","| Model No. |Training Labels|Output Neurons| Basic Model low / full| Naive Change Model | Retrained last layer Model | Fully Retrained (Transfer Learning) |\n","| :- |:--:|:--:| :-------------------------: | :-----------: | :-----------: |:-----------: |\n","| 1. | 10 | 10 | 0.9822 / 0.9804 | Same | 0.9824 / 0.9812 | 0.9819 / 0.9799 |\n","| 2. | 8  | 8  | 0.9864 / 0.7865 | 0.0441 / 0.0441 | 0.9683 / 0.9609 |  0.9784 / 0.9775  |\n","\n","0.6401 / 0.5343 for normally distributed weights on extra neurons"],"metadata":{"id":"G_atWiPry4Wb"}},{"cell_type":"markdown","source":["## Final Comparitive Results\n","(lower input with Higher Output 8/10 case)\n","\n","| Type of model | MNIST with CNN | MNIST 8/8 | CIFAR10 with CNN| CIFAR10 8/8 |MNIST with DNN | MNIST 8/8 |\n","| :- |:--:|:--:| :-------------------------: | :---: |:--:|:--:|\n","| Basic Model                        | 0.9896 / 0.7933 | 0.9936 / 0.7965 | 0.6990 / 0.5591\t| 0.6629 / 0.5303\t| 0.9822 / 0.9804\t|\t0.9864 / 0.7865 |\n","| Naive Change Model                 | 0.0051 / 0.0046 | 0.0834 / 0.0795 | 0.1558 / 0.1682 | 0.2137 / 0.1899\t| Same | 0.0441 / 0.0441\t|\n","| Retrained last layer Model         | 0.9874 / 0.9839 | 0.9903 / 0.9865 | 0.6736 / 0.6133\t| 0.6687 / 0.6075\t| 0.9824 / 0.9812 |  0.9683 / 0.9609|\n","| Fully Retrained (Transfer Learning)| 0.9918 / 0.9897 | 0.9909 / 0.9902 | 0.6698 / 0.6995 | 0.7101 / 0.7268 | 0.9819 / 0.9799 |\t0.9784 / 0.9775 |"],"metadata":{"id":"eu0bWoc3X63l"}},{"cell_type":"markdown","source":["## Conclusion\n"],"metadata":{"id":"lqOcDaYAwovB"}},{"cell_type":"markdown","source":["Same results as https://www.amazon.science/blog/updating-neural-networks-to-recognize-new-categories-with-minimal-retraining#:~:text=The%20first%20transfer%2Dlearning%20method,that%20uses%20the%20neural%20adapter.\n","\n"," the most effective technique is to keep the original classifier; pass its output through a separate network,\n","\n"," For both initial architectures and both transfer-learning methods, we considered the case in which we allowed only the weights of the top few layers to vary during retraining and the case in which we allowed the weights of the entire network to vary. Across the board, allowing all the weights to vary offered the best performance.\n","\n"," More Approaches - Ensemble based Approach, on older data model (few classes) and newer data model (all classes)"],"metadata":{"id":"RFnNKXS46CE4"}},{"cell_type":"markdown","source":["References :\n","* https://ai.stackexchange.com/questions/3981/is-it-possible-to-train-a-neural-network-as-new-classes-are-given\n","\n","* Chen, L., & Moschitti, A. (2019). Transfer learning for sequence labeling using source model and target data. Proceedings of the AAAI Conference on Artificial Intelligence, 33(01), 6260–6267. https://doi.org/10.1609/aaai.v33i01.33016260\n","\n","* https://stackoverflow.com/questions/50366160/re-train-model-with-new-classes?rq=3\n","Related section has more similar failed results.\n","* https://www.tensorflow.org/hub/tutorials/tf2_image_retraining\n","\n","Similar implementation -\n","* J. Zhang, F. Li, H. Wu and F. Ye, \"Autonomous Model Update Scheme for Deep Learning Based Network Traffic Classifiers,\" 2019 IEEE Global Communications Conference (GLOBECOM), Waikoloa, HI, USA, 2019, pp. 1-6, doi: 10.1109/GLOBECOM38437.2019.9014036 .\n","*  J. Zhang, F. Li, F. Ye and H. Wu, \"Autonomous Unknown-Application Filtering and Labeling for DL-based Traffic Classifier Update,\" IEEE INFOCOM 2020 - IEEE Conference on Computer Communications, Toronto, ON, Canada, 2020, pp. 397-405, doi: 10.1109/INFOCOM41043.2020.9155292 .\n"],"metadata":{"id":"z5TvC-eW1gym"}},{"cell_type":"markdown","source":["##  General Implementation"],"metadata":{"id":"jifNW8P8wBd1"}},{"cell_type":"code","source":["# Load MNIST dataset\n","mnist = tf.keras.datasets.mnist\n","(x_train_full, y_train_full), (x_test_full, y_test_full) = mnist.load_data()\n","\n","print(len(x_train_full))\n","print(len(x_test_full))\n","print(len(y_train_full))\n","print(len(y_test_full))"],"metadata":{"id":"6ECD-ShPvz3o","executionInfo":{"status":"ok","timestamp":1730584600292,"user_tz":-330,"elapsed":533,"user":{"displayName":"Yash Sarang","userId":"15641196399800805733"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"10975dde-5fda-49c5-ff06-d18921399e74"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["60000\n","10000\n","60000\n","10000\n"]}]},{"cell_type":"markdown","source":["### Creating  the variables\n"],"metadata":{"id":"mdH_e8NuvYRO"}},{"cell_type":"markdown","source":["Full = All labels\n","\n","Low = Labels 0-7\n","\n","High = Labels 8,9"],"metadata":{"id":"yGj0_JbqwqnN"}},{"cell_type":"markdown","source":["* x_train_full, x_test_full - **Original full testing dataset**\n","* x_train, x_test - **Train and Validation dataset**\n","* y_train_low, y_train_high\n","* y_test_low, y_test_high\n","* x_train_low, x_train_high\n","* x_test_low, x_test_high"],"metadata":{"id":"hSbmj34Awo6q"}},{"cell_type":"code","source":["# Normalize the data (0-255 to 0-1)\n","x_train_full, x_test_full = x_train_full / 255.0, x_test_full / 255.0\n","\n","# Flatten the images for the CNN model\n","x_train_full = x_train_full.reshape(-1, 28, 28, 1)\n","x_test_full = x_test_full.reshape(-1, 28, 28, 1)\n","\n","# Creating indices where the labels are in the range 0-7 : low, 8,9 : high\n","test_low_indices = np.where(y_test_full < 8)[0]\n","test_high_indices = np.where(y_test_full >= 8)[0]\n","\n","x_test_low = x_test_full[test_low_indices]\n","y_test_low = y_test_full[test_low_indices]\n","\n","x_test_high = x_test_full[test_high_indices]\n","y_test_high = y_test_full[test_high_indices]\n","\n","# Split the full training set into train and test sets with 80-20 split using a seed value\n","# Creating a training and validation set together\n","x_train, x_val, y_train, y_val = train_test_split(x_train_full, y_train_full, test_size=0.20, random_state=42)"],"metadata":{"id":"qgBVI1STv3R4","executionInfo":{"status":"ok","timestamp":1730584600950,"user_tz":-330,"elapsed":659,"user":{"displayName":"Yash Sarang","userId":"15641196399800805733"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["print(len(x_test_full))\n","print(len(x_test_low))\n","print(len(x_test_high),\"\\n\")\n","\n","print(len(y_test_full))\n","print(len(y_test_low))\n","print(len(y_test_high))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BXtrSN3W27kC","executionInfo":{"status":"ok","timestamp":1730584600950,"user_tz":-330,"elapsed":3,"user":{"displayName":"Yash Sarang","userId":"15641196399800805733"}},"outputId":"c7022e85-268d-4697-81cb-8ee9fd44fc7d"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["10000\n","8017\n","1983 \n","\n","10000\n","8017\n","1983\n"]}]},{"cell_type":"code","source":["# Create train_low (labels 0-7) and train_high (labels 8-9) from x_train\n","train_low_indices = np.where(y_train < 8)[0]\n","train_high_indices = np.where(y_train >= 8)[0]\n","\n","x_train_low = x_train[train_low_indices]\n","y_train_low = y_train[train_low_indices]\n","\n","x_train_high = x_train[train_high_indices]\n","y_train_high = y_train[train_high_indices]\n","\n","val_low_indices = np.where(y_val < 8)[0]\n","val_high_indices = np.where(y_val >= 8)[0]\n","\n","x_val_low = x_val[val_low_indices]\n","y_val_low = y_val[val_low_indices]\n","\n","x_val_high = x_val[val_high_indices]\n","y_val_high = y_val[val_high_indices]"],"metadata":{"id":"BV3CH9ZSwJjv","executionInfo":{"status":"ok","timestamp":1730584601557,"user_tz":-330,"elapsed":608,"user":{"displayName":"Yash Sarang","userId":"15641196399800805733"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["print(len(x_train))\n","print(len(x_train_low))\n","print(len(x_train_high),\"\\n\")\n","\n","print(len(y_train))\n","print(len(y_train_low))\n","print(len(y_train_high),\"\\n\")\n","\n","print(len(x_val))\n","print(len(x_val_low))\n","print(len(x_val_high),\"\\n\")\n","\n","print(len(y_val))\n","print(len(y_val_low))\n","print(len(y_val_high),\"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zvmqnq-P5gcW","executionInfo":{"status":"ok","timestamp":1730584601557,"user_tz":-330,"elapsed":2,"user":{"displayName":"Yash Sarang","userId":"15641196399800805733"}},"outputId":"99b49102-143b-4c26-b671-990a310bd2ca"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["48000\n","38554\n","9446 \n","\n","48000\n","38554\n","9446 \n","\n","12000\n","9646\n","2354 \n","\n","12000\n","9646\n","2354 \n","\n"]}]},{"cell_type":"markdown","source":["## 2. 8  labels - 8 outputs"],"metadata":{"id":"zh9s7FkaOe9g"}},{"cell_type":"code","source":["\n","# Define the initial model with 8 output neurons (for classes 0-7)\n","initial_model = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(128, activation='relu'),\n","    tf.keras.layers.Dense(8, activation='softmax')  # 8 classes for 0-7\n","])\n","\n","initial_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","initial_model.fit(x_train_low, y_train_low, epochs=5, validation_data=(x_val_low, y_val_low), batch_size=64)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jx7iegv21HZw","executionInfo":{"status":"ok","timestamp":1730584775088,"user_tz":-330,"elapsed":173107,"user":{"displayName":"Yash Sarang","userId":"15641196399800805733"}},"outputId":"e37632b5-03fd-4831-8f24-8392653b9770"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 42ms/step - accuracy: 0.9111 - loss: 0.3067 - val_accuracy: 0.9830 - val_loss: 0.0573\n","Epoch 2/5\n","\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 40ms/step - accuracy: 0.9845 - loss: 0.0482 - val_accuracy: 0.9867 - val_loss: 0.0438\n","Epoch 3/5\n","\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 41ms/step - accuracy: 0.9911 - loss: 0.0283 - val_accuracy: 0.9872 - val_loss: 0.0434\n","Epoch 4/5\n","\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 36ms/step - accuracy: 0.9950 - loss: 0.0165 - val_accuracy: 0.9908 - val_loss: 0.0313\n","Epoch 5/5\n","\u001b[1m603/603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 40ms/step - accuracy: 0.9964 - loss: 0.0120 - val_accuracy: 0.9912 - val_loss: 0.0313\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7e240edd74c0>"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["# Step 1: Calculate Fisher Information Matrix excluding the last layer's weights\n","def calculate_fisher_information(model, data, labels, batch_size=64):\n","    fisher_information = [np.zeros(layer.shape) for layer in model.trainable_weights[:-1]]  # Exclude last layer\n","    num_batches = len(data) // batch_size\n","    for i in range(num_batches):\n","        batch_data = data[i * batch_size:(i + 1) * batch_size]\n","        batch_labels = labels[i * batch_size:(i + 1) * batch_size]\n","\n","        with tf.GradientTape() as tape:\n","            predictions = model(batch_data)\n","            loss = tf.keras.losses.sparse_categorical_crossentropy(batch_labels, predictions)\n","\n","        gradients = tape.gradient(loss, model.trainable_weights[:-1])  # Exclude last layer\n","        for j, layer in enumerate(model.trainable_weights[:-1]):\n","            fisher_information[j] += np.square(gradients[j].numpy()) / num_batches\n","    return fisher_information\n","\n","# Recalculate fisher information and old weights without the last layer\n","fisher_information = calculate_fisher_information(initial_model, x_train_low, y_train_low)\n","old_weights = [layer.numpy() for layer in initial_model.trainable_weights[:-1]]  # Exclude last layer\n","\n","# Step 2: Modify the EWC loss function to use the adjusted fisher_information and old_weights\n","lambda_ewc = 0.5\n","\n","def ewc_loss(model, x, y):\n","    predictions = model(x)\n","    standard_loss = tf.keras.losses.sparse_categorical_crossentropy(y, predictions)\n","\n","    ewc_penalty = 0\n","    for i, layer in enumerate(model.trainable_weights[:-1]):  # Exclude last layer\n","        ewc_penalty += tf.reduce_sum(fisher_information[i] * tf.square(layer - old_weights[i]))\n","    ewc_penalty *= (lambda_ewc / 2)\n","\n","    return standard_loss + ewc_penalty\n","\n","# Custom training loop to apply EWC loss\n","class EWCLossModel(tf.keras.Sequential):\n","    def train_step(self, data):\n","        x, y = data\n","        with tf.GradientTape() as tape:\n","            loss = tf.reduce_mean(ewc_loss(self, x, y))\n","        gradients = tape.gradient(loss, self.trainable_variables)\n","        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n","        return {\"loss\": loss}\n","\n","# Initialize EWC model using the layers from second_model\n","ewc_model = EWCLossModel(second_model.layers)  # Pass layers directly\n","ewc_model.compile(optimizer='adam', metrics=['accuracy'])\n","\n","# Train the model on classes 8-9 with EWC regularization\n","ewc_model.fit(x_train_high, y_train_high, epochs=5, validation_data=(x_val_high, y_val_high))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":366},"id":"pTfsIgd81wjF","executionInfo":{"status":"error","timestamp":1730586190362,"user_tz":-330,"elapsed":33177,"user":{"displayName":"Yash Sarang","userId":"15641196399800805733"}},"outputId":"e561ac5e-919d-499f-b79d-0e221612f63b"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n"]},{"output_type":"error","ename":"ValueError","evalue":"Dimensions must be equal, but are 10 and 8 for '{{node sub_4}} = Sub[T=DT_FLOAT](ReadVariableOp_4, Const_8)' with input shapes: [128,10], [128,8].","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-7ac129968b12>\u001b[0m in \u001b[0;36m<cell line: 51>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# Train the model on classes 8-9 with EWC regularization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mewc_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_high\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_high\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val_high\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_high\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-23-7ac129968b12>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mewc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-23-7ac129968b12>\u001b[0m in \u001b[0;36mewc_loss\u001b[0;34m(model, x, y)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mewc_penalty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Exclude last layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mewc_penalty\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfisher_information\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mold_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mewc_penalty\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlambda_ewc\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 10 and 8 for '{{node sub_4}} = Sub[T=DT_FLOAT](ReadVariableOp_4, Const_8)' with input shapes: [128,10], [128,8]."]}]},{"cell_type":"code","source":["\n","# Custom training loop to apply EWC loss\n","class EWCLossModel(tf.keras.Model):\n","    def train_step(self, data):\n","        x, y = data\n","        with tf.GradientTape() as tape:\n","            loss = tf.reduce_mean(ewc_loss(self, x, y))\n","        gradients = tape.gradient(loss, self.trainable_variables)\n","        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n","        return {\"loss\": loss}\n","\n","# Use the second model architecture for EWC training\n","ewc_model = EWCLossModel(inputs=second_model.input, outputs=second_model.output)\n","ewc_model.compile(optimizer='adam', metrics=['accuracy'])\n","\n","# Train the model on classes 8-9 with EWC regularization\n","ewc_model.fit(x_train_high, y_train_high, epochs=5, validation_data=(x_val_high, y_val_high))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":384},"id":"SuV9mBxu5ToE","executionInfo":{"status":"error","timestamp":1730585043324,"user_tz":-330,"elapsed":1721,"user":{"displayName":"Yash Sarang","userId":"15641196399800805733"}},"outputId":"3af99d73-fe98-4515-dc01-ccc89b54595f"},"execution_count":19,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"The layer sequential_4 has never been called and thus has no defined input.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-63975aaac0f9>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Use the second model architecture for EWC training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mewc_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEWCLossModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msecond_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msecond_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mewc_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36minput\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mInput\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0minput\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \"\"\"\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_node_attribute_at_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input_tensors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36m_get_node_attribute_at_index\u001b[0;34m(self, node_index, attr, attr_name)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \"\"\"\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    286\u001b[0m                 \u001b[0;34mf\"The layer {self.name} has never been called \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m                 \u001b[0;34mf\"and thus has no defined {attr_name}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: The layer sequential_4 has never been called and thus has no defined input."]}]},{"cell_type":"markdown","source":["### Results"],"metadata":{"id":"1gpJqlgK6aS8"}},{"cell_type":"code","source":["show_misclassified_samples(model_2,x_test_low,y_test_low)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":228},"executionInfo":{"status":"ok","timestamp":1729700230079,"user_tz":-330,"elapsed":5461,"user":{"displayName":"Yash Sarang","userId":"15641196399800805733"}},"outputId":"639e52b4-f802-4d6b-d1e5-6e9896e5ae62","id":"cbDLsjC46aS9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n","Total misclassified samples: 147 out of 8017\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x1000 with 5 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["# Evaluate the model on the test set\n","test_loss, test_acc = model_2.evaluate(x_test_low, y_test_low)\n","print(f'Test accuracy over low dataset: {test_acc}, Test loss acc: {test_loss}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729700260996,"user_tz":-330,"elapsed":1209,"user":{"displayName":"Yash Sarang","userId":"15641196399800805733"}},"outputId":"5bd90016-6b3a-4911-de00-0aa539e2d439","id":"H-v2_WqZ6aS9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9807 - loss: 0.0831\n","Test accuracy over low dataset: 0.9816639423370361, Test loss acc: 0.07553794980049133\n"]}]},{"cell_type":"code","source":["# Evaluate the model on the test set\n","test_loss, test_acc = model_2.evaluate(x_test_full, y_test_full)\n","print(f'Test accuracy over whole dataset: {test_acc}, Test loss acc: {test_loss}')"],"metadata":{"id":"IceUbAzx6aS9","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1729700261718,"user_tz":-330,"elapsed":723,"user":{"displayName":"Yash Sarang","userId":"15641196399800805733"}},"outputId":"b4ec0b60-9503-4f95-ce50-8b7014541110"},"execution_count":null,"outputs":[{"output_type":"error","ename":"InvalidArgumentError","evalue":"Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-17-d952445dda52>\", line 2, in <cell line: 2>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 343, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 429, in evaluate\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 165, in one_step_on_iterator\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 154, in one_step_on_data\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 85, in test_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/trainer.py\", line 357, in _compute_loss\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/trainer.py\", line 325, in compute_loss\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/compile_utils.py\", line 609, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/compile_utils.py\", line 645, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses/loss.py\", line 43, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses/losses.py\", line 27, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses/losses.py\", line 1853, in sparse_categorical_crossentropy\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py\", line 1567, in sparse_categorical_crossentropy\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/nn.py\", line 645, in sparse_categorical_crossentropy\n\nReceived a label value of 9 which is outside the valid range of [0, 8).  Label values: 7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_one_step_on_iterator_5880]","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-581a682804c4>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Evaluate the model on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_full\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Test accuracy over whole dataset: {test_acc}, Test loss acc: {test_loss}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-17-d952445dda52>\", line 2, in <cell line: 2>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 343, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 429, in evaluate\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 165, in one_step_on_iterator\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 154, in one_step_on_data\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 85, in test_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/trainer.py\", line 357, in _compute_loss\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/trainer.py\", line 325, in compute_loss\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/compile_utils.py\", line 609, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/compile_utils.py\", line 645, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses/loss.py\", line 43, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses/losses.py\", line 27, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses/losses.py\", line 1853, in sparse_categorical_crossentropy\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py\", line 1567, in sparse_categorical_crossentropy\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/nn.py\", line 645, in sparse_categorical_crossentropy\n\nReceived a label value of 9 which is outside the valid range of [0, 8).  Label values: 7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_one_step_on_iterator_5880]"]}]},{"cell_type":"code","source":["accuracy_per_label(model_2)"],"metadata":{"id":"nKNffGoI6aS9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","pred_label_count(model_2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729700263679,"user_tz":-330,"elapsed":1539,"user":{"displayName":"Yash Sarang","userId":"15641196399800805733"}},"outputId":"5f163ac6-6e28-4c45-f06f-4e2daa5905f4","id":"EGlpPqTT6aS9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n","Label 0 was predicted 1057 times\n","Label 1 was predicted 1187 times\n","Label 2 was predicted 1136 times\n","Label 3 was predicted 1304 times\n","Label 4 was predicted 1571 times\n","Label 5 was predicted 1338 times\n","Label 6 was predicted 994 times\n","Label 7 was predicted 1413 times\n"]}]}]}