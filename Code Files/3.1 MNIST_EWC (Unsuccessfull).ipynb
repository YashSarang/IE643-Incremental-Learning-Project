{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["\n","# Final layer updation of a pre-trained model, if new classes come in the target dataset\n","\n"],"metadata":{"id":"YWKbJXOz_6og"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Subset\n","from torchvision import datasets, transforms\n","import numpy as np\n","\n","# Define a simple model for MNIST\n","class SimpleMLP(nn.Module):\n","    def __init__(self):\n","        super(SimpleMLP, self).__init__()\n","        self.fc1 = nn.Linear(28 * 28, 256)\n","        self.fc2 = nn.Linear(256, 128)\n","        self.fc3 = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","        x = x.view(-1, 28 * 28)\n","        x = torch.relu(self.fc1(x))\n","        x = torch.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","# Elastic Weight Consolidation class\n","class EWC:\n","    def __init__(self, model, dataloader, device='cpu'):\n","        self.model = model\n","        self.device = device\n","        self.dataloader = dataloader\n","        self.params = {n: p for n, p in self.model.named_parameters() if p.requires_grad}\n","        self._precision_matrices = self.compute_fisher_information()\n","        self.saved_params = {n: p.clone().detach() for n, p in self.params.items()}\n","\n","    def compute_fisher_information(self):\n","        fisher_matrices = {n: torch.zeros_like(p) for n, p in self.params.items()}\n","        self.model.eval()\n","\n","        for inputs, targets in self.dataloader:\n","            inputs, targets = inputs.to(self.device), targets.to(self.device)\n","            self.model.zero_grad()\n","            outputs = self.model(inputs)\n","            loss = nn.CrossEntropyLoss()(outputs, targets)\n","            loss.backward()\n","\n","            for n, p in self.model.named_parameters():\n","                fisher_matrices[n] += p.grad**2 / len(self.dataloader)\n","\n","        return fisher_matrices\n","\n","    def penalty(self):\n","        loss = 0\n","        for n, p in self.model.named_parameters():\n","            fisher = self._precision_matrices[n]\n","            loss += (fisher * (p - self.saved_params[n]) ** 2).sum()\n","        return loss\n","\n","# Function for training with EWC regularization\n","def train_ewc(model, train_loader, optimizer, ewc=None, lambda_ewc=0.4, device='cpu'):\n","    model.train()\n","    for inputs, targets in train_loader:\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        optimizer.zero_grad()\n","\n","        outputs = model(inputs)\n","        loss = nn.CrossEntropyLoss()(outputs, targets)\n","\n","        if ewc:\n","            loss += lambda_ewc * ewc.penalty()\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","# Evaluation function\n","def evaluate(model, test_loader, device='cpu'):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for inputs, targets in test_loader:\n","            inputs, targets = inputs.to(device), targets.to(device)\n","            outputs = model(inputs)\n","            _, predicted = outputs.max(1)\n","            total += targets.size(0)\n","            correct += (predicted == targets).sum().item()\n","    return correct / total\n"],"metadata":{"id":"IbFmqgxw1rtS","executionInfo":{"status":"ok","timestamp":1731154403909,"user_tz":-330,"elapsed":15868,"user":{"displayName":"Yash Durgadas Sarang","userId":"16508181367539698972"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["\n","# Loading and preprocessing MNIST\n","transform = transforms.Compose([transforms.ToTensor()])\n","train_set = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n","test_set = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n","\n","# Filter classes 0-7 for initial training\n","train_idx_0_7 = [i for i, t in enumerate(train_set.targets) if t < 8]\n","train_loader_0_7 = DataLoader(Subset(train_set, train_idx_0_7), batch_size=64, shuffle=True)\n","\n","# Filter classes 8-9 for new training\n","train_idx_8_9 = [i for i, t in enumerate(train_set.targets) if t >= 8]\n","train_loader_8_9 = DataLoader(Subset(train_set, train_idx_8_9), batch_size=64, shuffle=True)\n","\n","# Test loaders for different classes\n","test_idx_0_7 = [i for i, t in enumerate(test_set.targets) if t < 8]\n","test_loader_0_7 = DataLoader(Subset(test_set, test_idx_0_7), batch_size=64, shuffle=False)\n","\n","test_idx_8_9 = [i for i, t in enumerate(test_set.targets) if t >= 8]\n","test_loader_8_9 = DataLoader(Subset(test_set, test_idx_8_9), batch_size=64, shuffle=False)\n","\n","test_loader_all = DataLoader(test_set, batch_size=64, shuffle=False)\n","\n","# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Initialize model, optimizer\n","model = SimpleMLP().to(device)\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","\n","# Step 1: Train on classes 0-7\n","train_ewc(model, train_loader_0_7, optimizer, device=device)\n","accuracy_0_7 = evaluate(model, test_loader_0_7, device)\n","print(f'Accuracy on classes 0-7 after initial training: {accuracy_0_7:.4f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bgY5v--X1x1_","executionInfo":{"status":"ok","timestamp":1731154437577,"user_tz":-330,"elapsed":33697,"user":{"displayName":"Yash Durgadas Sarang","userId":"16508181367539698972"}},"outputId":"87bfffb4-75ba-425c-b38b-4ec7c6f79c3a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9.91M/9.91M [00:13<00:00, 762kB/s] \n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28.9k/28.9k [00:00<00:00, 135kB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1.65M/1.65M [00:01<00:00, 1.09MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4.54k/4.54k [00:00<00:00, 6.61MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","Accuracy on classes 0-7 after initial training: 0.9521\n"]}]},{"cell_type":"code","source":["# Set a higher lambda_ewc for stronger regularization\n","lambda_ewc = 5.0  # Increase to give higher priority to retaining initial knowledge\n","learning_rate = 0.001  # Reduce learning rate for EWC phase\n","\n","# Reinitialize optimizer with a lower learning rate for EWC retraining phase\n","optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n","\n","# Retrain on classes 8-9 with a higher EWC penalty\n","train_ewc(model, train_loader_8_9, optimizer, ewc=ewc, lambda_ewc=lambda_ewc, device=device)\n","\n","# Re-evaluate the model\n","accuracy_0_7_after = evaluate(model, test_loader_0_7, device)\n","accuracy_8_9 = evaluate(model, test_loader_8_9, device)\n","accuracy_all = evaluate(model, test_loader_all, device)\n","\n","print(f'Adjusted Accuracy on classes 0-7 after retraining on 8-9 with EWC: {accuracy_0_7_after:.4f}')\n","print(f'Adjusted Accuracy on classes 8-9 after retraining with EWC: {accuracy_8_9:.4f}')\n","print(f'Adjusted Overall accuracy after retraining with EWC: {accuracy_all:.4f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JqedUvYY118l","executionInfo":{"status":"ok","timestamp":1731154494951,"user_tz":-330,"elapsed":4281,"user":{"displayName":"Yash Durgadas Sarang","userId":"16508181367539698972"}},"outputId":"bbc17029-5718-47e0-fb70-d594e0e9e722"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Adjusted Accuracy on classes 0-7 after retraining on 8-9 with EWC: 0.0000\n","Adjusted Accuracy on classes 8-9 after retraining with EWC: 0.9793\n","Adjusted Overall accuracy after retraining with EWC: 0.1942\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Subset\n","from torchvision import datasets, transforms\n","import numpy as np\n","\n","class EWC:\n","    def __init__(self, model, dataloader, device='cpu'):\n","        self.model = model\n","        self.device = device\n","        self.dataloader = dataloader\n","        self.params = {n: p for n, p in self.model.named_parameters() if p.requires_grad}\n","        self.fisher_info = self.compute_fisher_information()\n","        self.saved_params = {n: p.clone().detach() for n, p in self.params.items()}\n","\n","    def compute_fisher_information(self):\n","        fisher_matrices = {n: torch.zeros_like(p) for n, p in self.params.items()}\n","        self.model.eval()\n","\n","        for inputs, targets in self.dataloader:\n","            inputs, targets = inputs.to(self.device), targets.to(self.device)\n","            self.model.zero_grad()\n","            outputs = self.model(inputs)\n","            loss = nn.CrossEntropyLoss()(outputs, targets)\n","            loss.backward()\n","\n","            for n, p in self.model.named_parameters():\n","                fisher_matrices[n] += p.grad**2 / len(self.dataloader)\n","\n","        return fisher_matrices\n","\n","    def penalty(self):\n","        loss = 0\n","        for n, p in self.model.named_parameters():\n","            fisher = self.fisher_info[n]\n","            # Adaptive EWC: applying stronger penalties to weights with high Fisher values\n","            importance = fisher * (p - self.saved_params[n]) ** 2\n","            loss += torch.sum(importance)\n","        return loss\n","\n","# Training with EWC regularization\n","def train_with_ewc(model, train_loader, optimizer, ewc=None, lambda_ewc=5.0, device='cpu'):\n","    model.train()\n","    for inputs, targets in train_loader:\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        optimizer.zero_grad()\n","\n","        outputs = model(inputs)\n","        loss = nn.CrossEntropyLoss()(outputs, targets)\n","\n","        # Apply EWC penalty\n","        if ewc:\n","            loss += lambda_ewc * ewc.penalty()\n","\n","        loss.backward()\n","        optimizer.step()\n","\n"],"metadata":{"id":"yJ-JOH6-14AO","executionInfo":{"status":"ok","timestamp":1731154601614,"user_tz":-330,"elapsed":640,"user":{"displayName":"Yash Durgadas Sarang","userId":"16508181367539698972"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["\n","# Evaluation function remains the same as previous code\n","\n","# Load MNIST and filter for classes 8-9\n","transform = transforms.Compose([transforms.ToTensor()])\n","train_set = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n","test_set = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n","\n","# Create dataloaders for classes 0-7 and 8-9\n","train_idx_0_7 = [i for i, t in enumerate(train_set.targets) if t < 8]\n","train_loader_0_7 = DataLoader(Subset(train_set, train_idx_0_7), batch_size=64, shuffle=True)\n","\n","train_idx_8_9 = [i for i, t in enumerate(train_set.targets) if t >= 8]\n","train_loader_8_9 = DataLoader(Subset(train_set, train_idx_8_9), batch_size=64, shuffle=True)\n","\n","test_idx_0_7 = [i for i, t in enumerate(test_set.targets) if t < 8]\n","test_loader_0_7 = DataLoader(Subset(test_set, test_idx_0_7), batch_size=64, shuffle=False)\n","\n","test_idx_8_9 = [i for i, t in enumerate(test_set.targets) if t >= 8]\n","test_loader_8_9 = DataLoader(Subset(test_set, test_idx_8_9), batch_size=64, shuffle=False)\n","\n","test_loader_all = DataLoader(test_set, batch_size=64, shuffle=False)\n","\n","# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Initialize model, optimizer, and Fisher Information for classes 0-7\n","model = SimpleMLP().to(device)\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","\n","# Step 1: Train on classes 0-7\n","train_with_ewc(model, train_loader_0_7, optimizer, device=device)\n","accuracy_0_7 = evaluate(model, test_loader_0_7, device)\n","print(f'Accuracy on classes 0-7 after initial training: {accuracy_0_7:.4f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mtP1QtbT2tLX","executionInfo":{"status":"ok","timestamp":1731154619580,"user_tz":-330,"elapsed":8971,"user":{"displayName":"Yash Durgadas Sarang","userId":"16508181367539698972"}},"outputId":"af37f5f1-f43a-4659-ba8c-62f87d8bd603"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy on classes 0-7 after initial training: 0.8699\n"]}]},{"cell_type":"code","source":["\n","# Step 2: Compute Fisher Information matrix for EWC\n","ewc = EWC(model, train_loader_0_7, device=device)\n","\n","# Step 3: Retrain on classes 8-9 using adaptive EWC\n","train_with_ewc(model, train_loader_8_9, optimizer, ewc=ewc, lambda_ewc=5.0, device=device)\n","\n","# Step 4: Evaluate the model on each test set\n","accuracy_0_7_after = evaluate(model, test_loader_0_7, device)\n","accuracy_8_9 = evaluate(model, test_loader_8_9, device)\n","accuracy_all = evaluate(model, test_loader_all, device)\n","\n","print(f'Adaptive EWC Accuracy on classes 0-7 after retraining on 8-9: {accuracy_0_7_after:.4f}')\n","print(f'Adaptive EWC Accuracy on classes 8-9 after retraining: {accuracy_8_9:.4f}')\n","print(f'Adaptive EWC Overall accuracy after retraining: {accuracy_all:.4f}')"],"metadata":{"id":"deEaSk312vqc","executionInfo":{"status":"ok","timestamp":1731154629705,"user_tz":-330,"elapsed":10133,"user":{"displayName":"Yash Durgadas Sarang","userId":"16508181367539698972"}},"outputId":"cf816b16-4d1c-41e0-d9de-8bcc7627aa69","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Adaptive EWC Accuracy on classes 0-7 after retraining on 8-9: 0.0000\n","Adaptive EWC Accuracy on classes 8-9 after retraining: 0.9465\n","Adaptive EWC Overall accuracy after retraining: 0.1877\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"dMQsXcBb2wgx"},"execution_count":null,"outputs":[]}]}